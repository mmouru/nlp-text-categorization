{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3.\tSuggest a script that uses tf-idf vectorizer of genism to calculate the similarity between the topic title and the abstract. Calculate the mean and standard deviation over all abstracts associated to the same topic. Provide the result in a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database\n",
    "\n",
    "db_file = \"./journal-database/database100_preprocessed.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "  \"mk\": \"Musculoskeletal Radiology\",\n",
    "  \"ct\": \"Computed Tomography\",\n",
    "  \"br\": \"Breast Imaging\",\n",
    "  \"gu\": \"Geritourinary Radiology\",\n",
    "  \"us\": \"Ultrasound\",\n",
    "  \"ch\": \"Chest Radiology\",\n",
    "  \"ir\": \"Interventional Radiology\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english') # initialize vectorizer\n",
    "similarity_values_abst = {}\n",
    "\n",
    "for topic in topics:\n",
    "    sheet = pd.read_excel(db_file, sheet_name=topic) # open correct sheet\n",
    "    similarity_values_abst[topic]=[] # init an empty array within the dictionary\n",
    "    for abstract in sheet.abstract:\n",
    "\n",
    "        content = [topics[topic]]                                   # create the\n",
    "        content.append(abstract)                                    # topic title/abstract pair\n",
    "\n",
    "        vectors = vectorizer.fit_transform(content)                 # learn vocabulary and idf, return document-term matrix\n",
    "\n",
    "        cosine_sim_matrix = cosine_similarity(vectors, vectors)     # calculate cosine similarity\n",
    "\n",
    "        similarity_values_abst[topic].append(cosine_sim_matrix[0][1])    # append calculated similarity value to list\n",
    "\n",
    "mean_and_sd_abst = {}\n",
    "\n",
    "# calculate mean and sd for each topic\n",
    "for topic in similarity_values_abst:\n",
    "    mean = np.mean(similarity_values_abst[topic])\n",
    "    sd = np.std(similarity_values_abst[topic])\n",
    "    mean_and_sd_abst[topic + \" (mean, sd)\"]=tuple((mean, sd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Repeat 3) when considering the title of the document instead of the abstract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english') # initialize vectorizer\n",
    "similarity_values_title = {}\n",
    "\n",
    "for topic in topics:\n",
    "    sheet = pd.read_excel(db_file, sheet_name=topic) # open correct sheet\n",
    "    similarity_values_title[topic]=[] # init an empty array within the dictionary\n",
    "    for title in sheet.title:\n",
    "\n",
    "        content = [topics[topic]]                                   # create the\n",
    "        content.append(title)                                    # topic title/abstract pair\n",
    "\n",
    "        vectors = vectorizer.fit_transform(content)                 # learn vocabulary and idf, return document-term matrix\n",
    "\n",
    "        cosine_sim_matrix = cosine_similarity(vectors, vectors)     # calculate cosine similarity\n",
    "\n",
    "        similarity_values_title[topic].append(cosine_sim_matrix[0][1])    # append calculated similarity value to list\n",
    "\n",
    "mean_and_sd_title = {}\n",
    "\n",
    "# calculate mean and sd for each topic\n",
    "for topic in similarity_values_title:\n",
    "    mean = np.mean(similarity_values_title[topic])\n",
    "    sd = np.std(similarity_values_title[topic])\n",
    "    mean_and_sd_title[topic + \" (mean, sd)\"]=tuple((mean, sd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table of the results from step 3. and step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity values of topic title and abstract to Excel table\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"similarity_table_abst.xlsx\")\n",
    "worksheet = workbook.add_worksheet(\"table\")\n",
    "worksheet.write(0, 1, 'Mean of similarity')\n",
    "worksheet.write(0, 2, 'Standard deviation (SD) of similarity')\n",
    "worksheet.write(0, 3, 'Sample size')\n",
    "\n",
    "for i, topic in enumerate(topics):\n",
    "    str = topics[topic] + \" \" + \"(\" + topic + \")\"\n",
    "    worksheet.write(i+1, 0, str)\n",
    "    sheet = pd.read_excel(db_file, sheet_name=topic) # open correct sheet\n",
    "    worksheet.write_number(i+1, 3, len(sheet))\n",
    "\n",
    "for j, stat in enumerate(mean_and_sd_abst):\n",
    "    worksheet.write_number(j+1, 1, mean_and_sd_abst[stat][0])\n",
    "    worksheet.write_number(j+1, 2, mean_and_sd_abst[stat][1])\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity values of topic title and document title to Excel table\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"similarity_table_title.xlsx\")\n",
    "worksheet = workbook.add_worksheet(\"table\")\n",
    "worksheet.write(0, 1, 'Mean of similarity')\n",
    "worksheet.write(0, 2, 'Standard deviation (SD) of similarity')\n",
    "worksheet.write(0, 3, 'Sample size')\n",
    "\n",
    "for i, topic in enumerate(topics):\n",
    "    str = topics[topic] + \" \" + \"(\" + topic + \")\"\n",
    "    worksheet.write(i+1, 0, str)\n",
    "    sheet = pd.read_excel(db_file, sheet_name=topic) # open correct sheet\n",
    "    worksheet.write_number(i+1, 3, len(sheet))\n",
    "\n",
    "for j, stat in enumerate(mean_and_sd_title):\n",
    "    worksheet.write_number(j+1, 1, mean_and_sd_title[stat][0])\n",
    "    worksheet.write_number(j+1, 2, mean_and_sd_title[stat][1])\n",
    "\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
